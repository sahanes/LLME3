<p align = "center" draggable=”false” ><img src="https://github.com/AI-Maker-Space/LLM-Dev-101/assets/37101144/d1343317-fa2f-41e1-8af1-1dbb18399719" 
     width="200px"
     height="auto"/>
</p>

<h1 align="center" id="heading"> 🚇 Session 8: Alignment</h1>

### [Quicklinks](https://github.com/AI-Maker-Space/LLM-Engineering-Foundations-to-SLMs/tree/main/00_AIM_Quicklinks)

| 🤓 Pre-work | 📰 Session Sheet | ⏺️ Recording     | 🖼️ Slides        | 👨‍💻 Repo         | 📝 Homework      | 📁 Feedback       |
|:-----------------|:-----------------|:-----------------|:-----------------|:-----------------|:-----------------|:-----------------|
| [Session 8: Pre-Work](https://www.notion.so/Session-8-Alignment-Coming-Soon-143cd547af3d8020820ac4f21a3068b5?pvs=4#e80e2e6ae82d4540adba08edd1a3b6bc) | [Session 8: Alignment ](https://www.notion.so/Session-8-Alignment-Coming-Soon-143cd547af3d8020820ac4f21a3068b5)  | [Recording](https://us02web.zoom.us/rec/component-page?action=viewdetailpage&sharelevel=meeting&useWhichPasswd=meeting&clusterId=us02&componentName=need-password&meetingId=QgYwwcLgQw0BmGvfhqApshe98YthoS29agneJ7OuNHA_z2313ckTPOhat9dmVRn8.FjPE-Av5ynfnUqq2&originRequestUrl=https%3A%2F%2Fus02web.zoom.us%2Frec%2Fshare%2FTrI1KuJU1kdifoqqUolquGOd9MzZR_fUecv1sSixWQ1FLBNhN06GjVy0DoFcKmee.v-zCG-BnqMWoJcom)  (V6IC2$*#)  |  [Session 8: Alignment](https://www.canva.com/design/DAGZHXVSNBE/ONsOxzgCW8Pqj5YFHfvP2Q/edit?utm_content=DAGZHXVSNBE&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton)  | You Are Here!  | [Session 8 Assignment: Alignment](https://forms.gle/g2kad4tuPEkzcWSW6) |  [Feedback: LLME3 Cohort, Session 8](https://forms.gle/aKRjP61cWuyoWRiD7) |

### Assignment: 

Today's assignments are available in Colab:
- Assignment #1: 
    - [Notebook #1 Assignment](https://colab.research.google.com/drive/1h4xq7cfBv9Gg_YPWvEPblP6fuCK2vjQy?usp=sharing)
    - [Notebook #2 Assignment](https://colab.research.google.com/drive/11qCfcABsxjjde7EihH6nHMH96aNBNONL?usp=sharing)
   
### Hardmode:

Take the [base](https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct) Llama 3.1 8B Instruct model and apply RLHF on it using a dataset of your choosing. 

> ENSURE THERE IS A EVALUATE METRIC ALIGNED WITH THE GOAL
>
> My Submission_01: Benchmarking For Toxicity: https://colab.research.google.com/drive/1x3PAmD0DZFlrLG4UdsQyAagd5kBPsdqx?usp=sharing

Evaluate a specific metric (using the Hugging Face `evaluate` library) to baseline your model - and then find out the delta due to the RLHF process.

> NOTE: This will consume a large volume of compute credits - and take a long time! Only embark on this journey if you really want to get deep into the weeds!
